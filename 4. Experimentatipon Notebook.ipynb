{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77b52427-190b-439d-acb0-445f9061e593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7432390c-946d-4c92-baf2-1871dbf5eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_pipeline(input_file:str = None,  \n",
    "                       target_column:str = None,\n",
    "                       input_type:str = \"csv\",\n",
    "                       training_type:str = \"clf\",\n",
    "                       engineer_new_features:bool = False, \n",
    "                       output_base:str = \"\", \n",
    "                       test_size:float = 0.2, \n",
    "                       no_standard_scaling:bool = False,\n",
    "                       feature_selection:bool = False, \n",
    "                       feature_selection_method:str = \"addition\",\n",
    "                       selectkbest_num_features: int = 32, \n",
    "                       output_dir:str = None,\n",
    "                       return_data:bool = False):\n",
    "    \"\"\"\n",
    "    Function to facilitate the training of multiple machine learning models,\n",
    "    optimize the models, and save the trained models. It also conducts model\n",
    "    evaluation using diverse methods. Additionally, the function is capable\n",
    "    of handling both regression and classification tasks.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Path to the input data in CSV/TSV format.\n",
    "        input_type (str): Type of input file format (csv or tsv).\n",
    "        training_type (str): Type of training (\"classification\" or \"regression\").\n",
    "        target_column (str): Name of the target column in the input dataframe.\n",
    "        engineer_new_features (bool, optional): Flag to perform engineering of\n",
    "            new features or not. Defaults to False.\n",
    "        output_base (str, optional): Base Name for most output files. Defaults to None.\n",
    "        test_size (float, optional): Fraction of the dataset to be used for testing.\n",
    "            Defaults to 0.2.\n",
    "        no_standard_scaling (bool, optional): Whether or not to apply scikit-learn\n",
    "            standard scaler on the data. Defaults to False.\n",
    "        feature_selection (bool, optional): Whether or not to perform feature\n",
    "            selection on the dataset. Defaults to False.\n",
    "        feature_selection_method (str, optional): Specify between recursive\n",
    "            feature addition and recursive feature elimination algorithms for\n",
    "            classification. Defaults to None.\n",
    "        selectkbest_num_features (int, optional): Number of top features to select.\n",
    "            For regression only. Defaults to None.\n",
    "        output_dir (str, optional): Custom Name of Output Folder. Defaults to None.\n",
    "        return_data (bool, optional): Select to include raw data, training data\n",
    "            and test data in the output folders. Defaults to False.\n",
    "    \"\"\"\n",
    "    if  feature_selection:\n",
    "        feature_selection = \" --feature_selection\"\n",
    "    else:\n",
    "        feature_selection = \"\"\n",
    "\n",
    "    if engineer_new_features:\n",
    "        engineer_new_features = \" --engineer_new_features\"\n",
    "    else:\n",
    "        engineer_new_features = \"\"\n",
    "\n",
    "    if no_standard_scaling:\n",
    "        no_standard_scaling = \" --no_standard_scaling\"\n",
    "    else:\n",
    "        no_standard_scaling = \"\"\n",
    "\n",
    "    if output_base == \"\":\n",
    "        output_base = f\" --output_base {training_type}\"\n",
    "    else:\n",
    "        output_base = f\" --output_base {output_base}\"\n",
    "        \n",
    "    # handle options\n",
    "    script = f\"run_train_pipeline --input_file {input_file} --target_column {target_column} --selectkbest_num_features {selectkbest_num_features} --training_type {training_type} --test_size {test_size} --feature_selection_method {feature_selection_method} --output_dir {output_dir}\" + feature_selection + engineer_new_features + no_standard_scaling + output_base\n",
    "\n",
    "    print(script)\n",
    "    # Your code to execute the training pipeline goes here\n",
    "    os.system(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab5b85bd-8fe0-4bdf-8f94-c6c9e9a63121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_train_pipeline --input_file data/data.csv --target_column incidence --selectkbest_num_features 32 --training_type reg --test_size 0.2 --feature_selection_method addition --output_dir outputs --output_base reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [05:38<00:00, 48.38s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n",
      "Best model cross validation score: 0.9531815048874028\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "run_train_pipeline(input_file = \"data/data.csv\",  \n",
    "                   target_column = \"incidence\",\n",
    "                   input_type = \"csv\",\n",
    "                   training_type = \"reg\",\n",
    "                   engineer_new_features=False,\n",
    "                   output_base=\"\",\n",
    "                   test_size=0.2, \n",
    "                   no_standard_scaling=False,\n",
    "                   feature_selection=False, \n",
    "                   feature_selection_method=\"addition\",\n",
    "                   selectkbest_num_features=32, \n",
    "                   output_dir=\"outputs\"\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1820d282-5a9c-49bb-b359-3ebad0c0ce01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>AvMeanSurAirTemp</th>\n",
       "      <th>AvMaxSurAirTemp</th>\n",
       "      <th>AvMinSurAirTemp</th>\n",
       "      <th>incidence</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Congo</td>\n",
       "      <td>1644.79</td>\n",
       "      <td>24.49</td>\n",
       "      <td>29.03</td>\n",
       "      <td>19.99</td>\n",
       "      <td>353.41557</td>\n",
       "      <td>15.827659</td>\n",
       "      <td>-0.228021</td>\n",
       "      <td>high incidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>Congo</td>\n",
       "      <td>1516.01</td>\n",
       "      <td>24.68</td>\n",
       "      <td>29.22</td>\n",
       "      <td>20.19</td>\n",
       "      <td>350.93625</td>\n",
       "      <td>15.827659</td>\n",
       "      <td>-0.228021</td>\n",
       "      <td>high incidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>Congo</td>\n",
       "      <td>1717.96</td>\n",
       "      <td>24.76</td>\n",
       "      <td>29.30</td>\n",
       "      <td>20.26</td>\n",
       "      <td>321.67402</td>\n",
       "      <td>15.827659</td>\n",
       "      <td>-0.228021</td>\n",
       "      <td>high incidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>Congo</td>\n",
       "      <td>1573.98</td>\n",
       "      <td>24.73</td>\n",
       "      <td>29.27</td>\n",
       "      <td>20.23</td>\n",
       "      <td>319.21132</td>\n",
       "      <td>15.827659</td>\n",
       "      <td>-0.228021</td>\n",
       "      <td>high incidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>Congo</td>\n",
       "      <td>1507.59</td>\n",
       "      <td>24.83</td>\n",
       "      <td>29.37</td>\n",
       "      <td>20.33</td>\n",
       "      <td>317.81208</td>\n",
       "      <td>15.827659</td>\n",
       "      <td>-0.228021</td>\n",
       "      <td>high incidence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year country  precipitation  AvMeanSurAirTemp  AvMaxSurAirTemp  \\\n",
       "0  2000   Congo        1644.79             24.49            29.03   \n",
       "1  2001   Congo        1516.01             24.68            29.22   \n",
       "2  2002   Congo        1717.96             24.76            29.30   \n",
       "3  2003   Congo        1573.98             24.73            29.27   \n",
       "4  2004   Congo        1507.59             24.83            29.37   \n",
       "\n",
       "   AvMinSurAirTemp  incidence  longitude  latitude           group  \n",
       "0            19.99  353.41557  15.827659 -0.228021  high incidence  \n",
       "1            20.19  350.93625  15.827659 -0.228021  high incidence  \n",
       "2            20.26  321.67402  15.827659 -0.228021  high incidence  \n",
       "3            20.23  319.21132  15.827659 -0.228021  high incidence  \n",
       "4            20.33  317.81208  15.827659 -0.228021  high incidence  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "data = pd.read_csv(\"data/data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7a6bce8-e27b-44af-96d4-be2033c9b597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "# make directories\n",
    "classification_path = \"data/classification\"\n",
    "regression_path = \"data/regression\"\n",
    "os.makedirs(classification_path,exist_ok=True)\n",
    "os.makedirs(regression_path,exist_ok=True)\n",
    "\n",
    "# prepare regression data\n",
    "# with both country and year columns\n",
    "reg1 = data.drop([\"group\"], axis = 1)\n",
    "reg1.to_csv(\"data/regression/reg1.csv\", index = False)\n",
    "\n",
    "# without country column\n",
    "reg2 = data.drop([\"group\", \"country\"], axis = 1)\n",
    "reg2.to_csv(\"data/regression/reg2.csv\", index = False)\n",
    "\n",
    "# without year column\n",
    "reg3 = data.drop([\"group\", \"year\"], axis = 1)\n",
    "reg3.to_csv(\"data/regression/reg3.csv\", index = False)\n",
    "\n",
    "# without both country and year columns\n",
    "reg4 = data.drop([\"group\", \"year\", \"country\"], axis = 1)\n",
    "reg4.to_csv(\"data/regression/reg4.csv\", index = False)\n",
    "\n",
    "# prepare classification data\n",
    "# with both country and year columns\n",
    "clf1 = data.drop([\"incidence\"], axis = 1)\n",
    "clf1.to_csv(\"data/classification/clf1.csv\", index = False)\n",
    "\n",
    "# without country column\n",
    "clf2 = data.drop([\"incidence\", \"country\"], axis = 1)\n",
    "clf2.to_csv(\"data/classification/clf2.csv\", index = False)\n",
    "\n",
    "# without year column\n",
    "clf3 = data.drop([\"incidence\", \"year\"], axis = 1)\n",
    "clf3.to_csv(\"data/classification/clf3.csv\", index = False)\n",
    "\n",
    "# without both country and year columns\n",
    "clf4 = data.drop([\"incidence\", \"year\", \"country\"], axis = 1)\n",
    "clf4.to_csv(\"data/classification/clf4.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82567e7b-b817-4c60-b65a-282026db8ae9",
   "metadata": {},
   "source": [
    "## Experiment 1: How does the Year and Country Info Affect Model Performance?\n",
    "### A. Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7f54f1e-1be7-408f-878e-d6bdd945f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Experiments\n",
    "# make experiment output directory\n",
    "experiment1_output_path = \"data/regression/Experiment1\"\n",
    "os.makedirs(experiment1_output_path,exist_ok=True)\n",
    "\n",
    "\n",
    "experiment_config = {\n",
    "    \"with year and country\": \"data/regression/reg1.csv\",\n",
    "    \"with year and without country\": \"data/regression/reg2.csv\",\n",
    "    \"without year and with country\": \"data/regression/reg3.csv\",\n",
    "    \"without year and without country\": \"data/regression/reg4.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8267e006-b63b-4448-b63a-24da2752e17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c316826ec2dd46d1a2ac775f84151ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Models with year and country data\n",
      "run_train_pipeline --input_file data/regression/reg1.csv --target_column incidence --selectkbest_num_features 32 --training_type reg --test_size 0.2 --feature_selection_method addition --output_dir data/regression/reg1 --output_base reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [07:16<00:00, 62.35s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n",
      "Best model cross validation score: 0.9553503102274707\n",
      "\n",
      "Training Models with year and without country data\n",
      "run_train_pipeline --input_file data/regression/reg2.csv --target_column incidence --selectkbest_num_features 32 --training_type reg --test_size 0.2 --feature_selection_method addition --output_dir data/regression/reg2 --output_base reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [04:23<00:00, 37.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: CatBoosting Regressor\n",
      "Best model cross validation score: 0.9538056179981247\n",
      "\n",
      "Training Models without year and with country data\n",
      "run_train_pipeline --input_file data/regression/reg3.csv --target_column incidence --selectkbest_num_features 32 --training_type reg --test_size 0.2 --feature_selection_method addition --output_dir data/regression/reg3 --output_base reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [06:05<00:00, 52.15s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Gradient Boosting\n",
      "Best model cross validation score: 0.8748943182645273\n",
      "\n",
      "Training Models without year and without country data\n",
      "run_train_pipeline --input_file data/regression/reg4.csv --target_column incidence --selectkbest_num_features 32 --training_type reg --test_size 0.2 --feature_selection_method addition --output_dir data/regression/reg4 --output_base reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [03:34<00:00, 30.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: CatBoosting Regressor\n",
      "Best model cross validation score: 0.8714057203433427\n"
     ]
    }
   ],
   "source": [
    "# Run Experiments\n",
    "for experiment_name, data_path in tqdm(experiment_config.items()):\n",
    "    print(f\"\\nTraining Models {experiment_name} data\")\n",
    "    outdir = os.path.join(experiment1_output_path, os.path.basename(data_path).split(\".\")[0])\n",
    "    # run experiment\n",
    "    run_train_pipeline(input_file = data_path,  \n",
    "                       target_column = \"incidence\",\n",
    "                       input_type = \"csv\",\n",
    "                       training_type = \"reg\",\n",
    "                       engineer_new_features=False,\n",
    "                       output_base=\"\",\n",
    "                       test_size=0.2, \n",
    "                       no_standard_scaling=False,\n",
    "                       feature_selection=False, \n",
    "                       feature_selection_method=\"addition\",\n",
    "                       selectkbest_num_features=32, \n",
    "                       output_dir=outdir\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7746d9a-1890-4c4b-8712-90e144a54189",
   "metadata": {},
   "source": [
    "It seems making use of both the year and country columns affects the model performance in a positive way. While removing the year column affects the models very badly, removing the country column affects it only slightly. This may be due to the fact that other country data such as longitude and latitude are still being used. If similar results are produced in classification, then the country column can be discarded. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a4a936-553a-4366-a70c-aac1c7853e1a",
   "metadata": {},
   "source": [
    "### B. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c562f145-2517-47eb-b4ac-43a10a37f0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Experiments\n",
    "# make experiment output directory\n",
    "experiment1_output_path = \"data/classification/Experiment1\"\n",
    "os.makedirs(experiment1_output_path,exist_ok=True)\n",
    "\n",
    "\n",
    "experiment_config = {\n",
    "    \"with year and country\": \"data/classification/clf1.csv\",\n",
    "    \"with year and without country\": \"data/classification/clf2.csv\",\n",
    "    \"without year and with country\": \"data/classification/clf3.csv\",\n",
    "    \"without year and without country\": \"data/classification/clf4.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dc175ed-3518-4fea-93a1-a79f16ffc44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20ae2bb8b8f427f865ed2b48e3355cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Models with year and country data\n",
      "run_train_pipeline --input_file data/classification/clf1.csv --target_column group --selectkbest_num_features 32 --training_type clf --test_size 0.2 --feature_selection_method addition --output_dir data/classification/clf1 --output_base clf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [06:38<00:00, 44.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: MLPClassifier\n",
      "Best model cross validation score: 0.9685672434312919\n",
      "\n",
      "Training Models with year and without country data\n",
      "run_train_pipeline --input_file data/classification/clf2.csv --target_column group --selectkbest_num_features 32 --training_type clf --test_size 0.2 --feature_selection_method addition --output_dir data/classification/clf2 --output_base clf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [05:01<00:00, 33.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: XGBClassifier\n",
      "Best model cross validation score: 0.9576764625102994\n",
      "\n",
      "Training Models without year and with country data\n",
      "run_train_pipeline --input_file data/classification/clf3.csv --target_column group --selectkbest_num_features 32 --training_type clf --test_size 0.2 --feature_selection_method addition --output_dir data/classification/clf3 --output_base clf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [05:11<00:00, 34.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: MLPClassifier\n",
      "Best model cross validation score: 0.9256394763343405\n",
      "\n",
      "Training Models without year and without country data\n",
      "run_train_pipeline --input_file data/classification/clf4.csv --target_column group --selectkbest_num_features 32 --training_type clf --test_size 0.2 --feature_selection_method addition --output_dir data/classification/clf4 --output_base clf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [04:38<00:00, 30.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n",
      "Best model cross validation score: 0.922012267692026\n"
     ]
    }
   ],
   "source": [
    "# Run Experiments\n",
    "for experiment_name, data_path in tqdm(experiment_config.items()):\n",
    "    print(f\"\\nTraining Models {experiment_name} data\")\n",
    "    outdir = os.path.join(experiment1_output_path, os.path.basename(data_path).split(\".\")[0])\n",
    "    # run experiment\n",
    "    run_train_pipeline(input_file = data_path,  \n",
    "                       target_column = \"group\",\n",
    "                       input_type = \"csv\",\n",
    "                       training_type = \"clf\",\n",
    "                       engineer_new_features=False,\n",
    "                       output_base=\"\",\n",
    "                       test_size=0.2, \n",
    "                       no_standard_scaling=False,\n",
    "                       feature_selection=False, \n",
    "                       feature_selection_method=\"addition\",\n",
    "                       selectkbest_num_features=32, \n",
    "                       output_dir=outdir\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ceeef2-6a74-480c-b11f-c319956178a2",
   "metadata": {},
   "source": [
    "It seems like country and year column affect classification the same way as it affects regression. Hover, removing the country column seems to drop the accuracy significantly. Moreover, for comparative studies, we will keep both the year and country columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea4ad4a-f726-4b65-921b-ff4cdcc629de",
   "metadata": {},
   "source": [
    "## Experiment 2: How Does Data Normalization Affect Model Performance\n",
    "### A. Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8931fdf-ad0a-4673-b765-612c7a0516a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Experiments\n",
    "# make experiment output directory\n",
    "experiment2_output_path = \"data/regression/Experiment2\"\n",
    "os.makedirs(experiment2_output_path,exist_ok=True)\n",
    "\n",
    "experiment_config = {\n",
    "    \"with normalization\": {\"no_standard_scaling\": False, \"output_dir\": \"data/regression/Experiment2/standard_scaling\"},\n",
    "    \"without normalization\": {\"no_standard_scaling\":True, \"output_dir\": \"data/regression/Experiment2/no_standard_scaling\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "caf54b7b-0add-4618-bec4-66c2c8601d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458d486bcd3c4ef3950aec681e5ff0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Models data with normalization\n",
      "run_train_pipeline --input_file data/regression/reg1.csv --target_column incidence --selectkbest_num_features 32 --training_type reg --test_size 0.2 --feature_selection_method addition --output_dir data/regression/Experiment2/standard_scaling --output_base reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [06:24<00:00, 55.00s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n",
      "Best model cross validation score: 0.9553503102274707\n",
      "\n",
      "Training Models data without normalization\n",
      "run_train_pipeline --input_file data/regression/reg1.csv --target_column incidence --selectkbest_num_features 32 --training_type reg --test_size 0.2 --feature_selection_method addition --output_dir data/regression/Experiment2/no_standard_scaling --no_standard_scaling --output_base reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [06:15<00:00, 53.66s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n",
      "Best model cross validation score: 0.9566985202775051\n"
     ]
    }
   ],
   "source": [
    "# Run Experiments\n",
    "data_path = \"data/regression/reg1.csv\"\n",
    "for experiment_name, config in tqdm(experiment_config.items()):\n",
    "    print(f\"\\nTraining Models {experiment_name} data\")\n",
    "    outdir = config[\"output_dir\"]\n",
    "    no_standard_scaling = config[\"no_standard_scaling\"]\n",
    "    # run experiment\n",
    "    run_train_pipeline(input_file = data_path,  \n",
    "                       target_column = \"incidence\",\n",
    "                       input_type = \"csv\",\n",
    "                       training_type = \"reg\",\n",
    "                       engineer_new_features=False,\n",
    "                       output_base=\"\",\n",
    "                       test_size=0.2, \n",
    "                       no_standard_scaling=no_standard_scaling,\n",
    "                       feature_selection=False, \n",
    "                       feature_selection_method=\"addition\",\n",
    "                       selectkbest_num_features=32, \n",
    "                       output_dir=outdir\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b2e9ac-6eb9-4e14-9eda-a8b7a9a38ee0",
   "metadata": {},
   "source": [
    "### B. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b13d1e0d-4145-474a-b71e-f43a019f78bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Experiments\n",
    "# make experiment output directory\n",
    "experiment2_output_path = \"data/classification/Experiment2\"\n",
    "os.makedirs(experiment2_output_path,exist_ok=True)\n",
    "\n",
    "experiment_config = {\n",
    "    \"with normalization\": {\"no_standard_scaling\": False, \"output_dir\": \"data/classification/Experiment2/standard_scaling\"},\n",
    "    \"without normalization\": {\"no_standard_scaling\":True, \"output_dir\": \"data/classification/Experiment2/no_standard_scaling\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d31e9db-5e19-479e-b834-9a3226f98f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07cdfd4c0b246a996cdcb5ad6414633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Models with normalization data\n",
      "run_train_pipeline --input_file data/classification/clf1.csv --target_column group --selectkbest_num_features 32 --training_type clf --test_size 0.2 --feature_selection_method addition --output_dir data/classification/Experiment2/standard_scaling --output_base clf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [05:59<00:00, 39.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: MLPClassifier\n",
      "Best model cross validation score: 0.9685672434312919\n",
      "\n",
      "Training Models without normalization data\n",
      "run_train_pipeline --input_file data/classification/clf1.csv --target_column group --selectkbest_num_features 32 --training_type clf --test_size 0.2 --feature_selection_method addition --output_dir data/classification/Experiment2/no_standard_scaling --no_standard_scaling --output_base clf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [06:22<00:00, 42.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: CatBoosting Classifier\n",
      "Best model cross validation score: 0.9661484940034789\n"
     ]
    }
   ],
   "source": [
    "# Run Experiments\n",
    "data_path = \"data/classification/clf1.csv\"\n",
    "for experiment_name, config in tqdm(experiment_config.items()):\n",
    "    print(f\"\\nTraining Models {experiment_name} data\")\n",
    "    outdir = config[\"output_dir\"]\n",
    "    no_standard_scaling = config[\"no_standard_scaling\"]\n",
    "    # run experiment\n",
    "    run_train_pipeline(input_file = data_path,  \n",
    "                       target_column = \"group\",\n",
    "                       input_type = \"csv\",\n",
    "                       training_type = \"clf\",\n",
    "                       engineer_new_features=False,\n",
    "                       output_base=\"\",\n",
    "                       test_size=0.2, \n",
    "                       no_standard_scaling=no_standard_scaling,\n",
    "                       feature_selection=False, \n",
    "                       feature_selection_method=\"addition\",\n",
    "                       selectkbest_num_features=32, \n",
    "                       output_dir=outdir\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ae462d-ded1-4a64-95ff-781ec017d121",
   "metadata": {},
   "source": [
    "From the above results, normalization affects regression model performance slighly positively while the reverse in true for classification. However, in research findings, normalization has shown to generally yield better results. Therefore, we will implement normalization on our project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd72281f-6d21-44da-95aa-7928fa6968a0",
   "metadata": {},
   "source": [
    "## Experiment 3: How Does Feature Engineering Affect Model Performance?\n",
    "### A. Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "570e4b43-a459-4299-a4d8-2139cec9633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Experiments\n",
    "# make experiment output directory\n",
    "experiment3_output_path = \"data/regression/Experiment3\"\n",
    "os.makedirs(experiment3_output_path,exist_ok=True)\n",
    "\n",
    "experiment_config = {\n",
    "    \"with featuring engineering\": {\"engineer_new_features\": True, \"output_dir\": \"data/regression/Experiment3/feature-engineering\"},\n",
    "    \"without feature engineering\": {\"engineer_new_features\": False, \"output_dir\": \"data/regression/Experiment3/no-feature-engineering\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "061d6a45-b78c-491e-9806-b108c0b767e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8718ef70e2a4ecc9b9694064a196c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Models with featuring engineering on data\n",
      "run_train_pipeline --input_file data/regression/reg1.csv --target_column incidence --selectkbest_num_features 32 --training_type reg --test_size 0.2 --feature_selection_method addition --output_dir data/regression/Experiment3/feature-engineering --engineer_new_features --output_base reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [38:52<00:00, 333.18s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: CatBoosting Regressor\n",
      "Best model cross validation score: 0.9535993097575188\n",
      "\n",
      "Training Models without feature engineering on data\n",
      "run_train_pipeline --input_file data/regression/reg1.csv --target_column incidence --selectkbest_num_features 32 --training_type reg --test_size 0.2 --feature_selection_method addition --output_dir data/regression/Experiment3/no-feature-engineering --output_base reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [06:04<00:00, 52.13s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n",
      "Best model cross validation score: 0.9553503102274707\n"
     ]
    }
   ],
   "source": [
    "# Run Experiments\n",
    "data_path = \"data/regression/reg1.csv\"\n",
    "for experiment_name, config in tqdm(experiment_config.items()):\n",
    "    print(f\"\\nTraining Models {experiment_name} on data\")\n",
    "    outdir = config[\"output_dir\"]\n",
    "    engineer_new_features = config[\"engineer_new_features\"]\n",
    "    # run experiment\n",
    "    run_train_pipeline(input_file = data_path,  \n",
    "                       target_column = \"incidence\",\n",
    "                       input_type = \"csv\",\n",
    "                       training_type = \"reg\",\n",
    "                       engineer_new_features=engineer_new_features,\n",
    "                       output_base=\"\",\n",
    "                       test_size=0.2, \n",
    "                       no_standard_scaling=False,\n",
    "                       feature_selection=False, \n",
    "                       feature_selection_method=\"addition\",\n",
    "                       selectkbest_num_features=32, \n",
    "                       output_dir=outdir\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbdca39-202d-42d8-9d3a-c6a09bf65cea",
   "metadata": {},
   "source": [
    "### B. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6255ef7a-2626-4e98-b26a-1a7449089ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Experiments\n",
    "# make experiment output directory\n",
    "experiment3_output_path = \"data/classification/Experiment3\"\n",
    "os.makedirs(experiment3_output_path,exist_ok=True)\n",
    "\n",
    "experiment_config = {\n",
    "    \"with featuring engineering\": {\"engineer_new_features\": True, \"output_dir\": \"data/classification/Experiment3/feature-engineering\"},\n",
    "    \"without feature engineering\": {\"engineer_new_features\": False, \"output_dir\": \"data/classification/Experiment3/no-feature-engineering\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fad9d03d-6043-4302-853f-868dc99487a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b3dfbdb7ac4a068001bfb50a282ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Models with featuring engineering on data\n",
      "run_train_pipeline --input_file data/classification/clf1.csv --target_column group --selectkbest_num_features 32 --training_type clf --test_size 0.2 --feature_selection_method addition --output_dir data/classification/Experiment3/feature-engineering --engineer_new_features --output_base clf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [23:55<00:00, 159.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: XGBClassifier\n",
      "Best model cross validation score: 0.9673551222191706\n",
      "\n",
      "Training Models without feature engineering on data\n",
      "run_train_pipeline --input_file data/classification/clf1.csv --target_column group --selectkbest_num_features 32 --training_type clf --test_size 0.2 --feature_selection_method addition --output_dir data/classification/Experiment3/no-feature-engineering --output_base clf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [06:22<00:00, 42.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: MLPClassifier\n",
      "Best model cross validation score: 0.9685672434312919\n"
     ]
    }
   ],
   "source": [
    "# Run Experiments\n",
    "data_path = \"data/classification/clf1.csv\"\n",
    "for experiment_name, config in tqdm(experiment_config.items()):\n",
    "    print(f\"\\nTraining Models {experiment_name} on data\")\n",
    "    outdir = config[\"output_dir\"]\n",
    "    engineer_new_features = config[\"engineer_new_features\"]\n",
    "    # run experiment\n",
    "    run_train_pipeline(input_file = data_path,  \n",
    "                       target_column = \"group\",\n",
    "                       input_type = \"csv\",\n",
    "                       training_type = \"clf\",\n",
    "                       engineer_new_features=engineer_new_features,\n",
    "                       output_base=\"\",\n",
    "                       test_size=0.2, \n",
    "                       no_standard_scaling=False,\n",
    "                       feature_selection=False, \n",
    "                       feature_selection_method=\"addition\",\n",
    "                       selectkbest_num_features=32, \n",
    "                       output_dir=outdir\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379b4314-7c90-469c-971d-0a9393396bef",
   "metadata": {},
   "source": [
    "Apparently, feature engineering does not improve results. In fact, using the original dataset performs better than engineering new features. However, will try to perform future selection on the engineered futures to see if the performance would increase. Normally, feature selection could be applied on the original dataset as well, but our dataset already has a small number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fd1828-06e1-41d3-b561-fdc0907abffe",
   "metadata": {},
   "source": [
    "## Experiment 4: How does Feature Selection Affect Model Performance?\n",
    "Since we already have results for no feature selection, we will only perform experiments for the different feature selection methods and options.\n",
    "### A. Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b5e2ee3-d36c-4554-81ff-59785f4e8355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Experiments\n",
    "# make experiment output directory\n",
    "experiment4_output_path = \"data/regression/Experiment4\"\n",
    "os.makedirs(experiment4_output_path,exist_ok=True)\n",
    "\n",
    "experiment_config = {\n",
    "    \"with featuring selection\": {\"feature_selection\": True, \n",
    "                                 \"output_dir\": \"data/regression/Experiment4/feature_selection\",\n",
    "                                 \"engineer_new_features\": True,\n",
    "                                 \"num_features\": [8,16,32, 64]\n",
    "                                },\n",
    "    \"without feature selection\": {\"feature_selection\": False, \n",
    "                                  \"output_dir\": \"data/regression/Experiment4/no_feature_selection\",\n",
    "                                  \"engineer_new_features\":False,\n",
    "                                  \"num_features\": [32]\n",
    "                                 }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "08e0579c-96a3-47db-a561-515093f98444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b8bdd31d8346d9a81563c142a93946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Models with featuring selection on data\n",
      "run_train_pipeline --input_file data/regression/reg1.csv --target_column incidence --selectkbest_num_features 8 --training_type reg --test_size 0.2 --feature_selection_method addition --output_dir data/regression/Experiment4/feature_selection_8 --feature_selection --engineer_new_features --output_base reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [04:46<00:00, 40.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: XGBRegressor\n",
      "Best model cross validation score: 0.842113285417654\n",
      "run_train_pipeline --input_file data/regression/reg1.csv --target_column incidence --selectkbest_num_features 16 --training_type reg --test_size 0.2 --feature_selection_method addition --output_dir data/regression/Experiment4/feature_selection_16 --feature_selection --engineer_new_features --output_base reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [09:09<00:00, 78.57s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: XGBRegressor\n",
      "Best model cross validation score: 0.8745290372774303\n",
      "run_train_pipeline --input_file data/regression/reg1.csv --target_column incidence --selectkbest_num_features 32 --training_type reg --test_size 0.2 --feature_selection_method addition --output_dir data/regression/Experiment4/feature_selection_32 --feature_selection --engineer_new_features --output_base reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [15:12<00:00, 130.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n",
      "Best model cross validation score: 0.9321241616037724\n",
      "run_train_pipeline --input_file data/regression/reg1.csv --target_column incidence --selectkbest_num_features 64 --training_type reg --test_size 0.2 --feature_selection_method addition --output_dir data/regression/Experiment4/feature_selection_64 --feature_selection --engineer_new_features --output_base reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [22:57<00:00, 196.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: XGBRegressor\n",
      "Best model cross validation score: 0.9565538811032365\n",
      "\n",
      "Training Models without feature selection on data\n",
      "run_train_pipeline --input_file data/regression/reg1.csv --target_column incidence --selectkbest_num_features 32 --training_type reg --test_size 0.2 --feature_selection_method addition --output_dir data/regression/Experiment4/no_feature_selection_32 --output_base reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [06:00<00:00, 51.51s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n",
      "Best model cross validation score: 0.9553503102274707\n"
     ]
    }
   ],
   "source": [
    "# Run Experiments\n",
    "data_path = \"data/regression/reg1.csv\"\n",
    "for experiment_name, config in tqdm(experiment_config.items()):\n",
    "    print(f\"\\nTraining Models {experiment_name} on data\")\n",
    "    \n",
    "    engineer_new_features = config[\"engineer_new_features\"]\n",
    "    feature_selection = config[\"feature_selection\"]\n",
    "    num_features_list = config[\"num_features\"]\n",
    "\n",
    "    for num_features in num_features_list:\n",
    "        outdir = config[\"output_dir\"] + f\"_{num_features}\"\n",
    "        # run experiment\n",
    "        run_train_pipeline(input_file = data_path,  \n",
    "                           target_column = \"incidence\",\n",
    "                           input_type = \"csv\",\n",
    "                           training_type = \"reg\",\n",
    "                           engineer_new_features=engineer_new_features,\n",
    "                           output_base=\"\",\n",
    "                           test_size=0.2, \n",
    "                           no_standard_scaling=False,\n",
    "                           feature_selection=feature_selection, \n",
    "                           feature_selection_method=\"addition\",\n",
    "                           selectkbest_num_features=num_features, \n",
    "                           output_dir=outdir\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b986c-9d20-4d33-a5d8-91085c66f89e",
   "metadata": {},
   "source": [
    "### B. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "64e540d7-d428-4e2c-8d32-7bce57ea1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Experiments\n",
    "# make experiment output directory\n",
    "experiment4_output_path = \"data/classification/Experiment4\"\n",
    "os.makedirs(experiment4_output_path,exist_ok=True)\n",
    "\n",
    "experiment_config = {\n",
    "    \"without feature selection\": {\"feature_selection\": False, \n",
    "                                  \"output_dir\": \"data/classification/Experiment4/no_feature_selection\",\n",
    "                                  \"engineer_new_features\":False,\n",
    "                                  \"feature_selection_method\": [\"addition\"]\n",
    "                                 },\n",
    "    \"with featuring selection\": {\"feature_selection\": True, \n",
    "                                 \"output_dir\": \"data/classification/Experiment4/feature_selection\",\n",
    "                                 \"engineer_new_features\": True,\n",
    "                                 \"feature_selection_method\": [\"addition\", \"elimination\"]\n",
    "                                }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0aac4721-c6a7-46d8-9d37-8992a200eb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd6daa07ad948b8a39249efe93d653a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Models without feature selection on data\n",
      "run_train_pipeline --input_file data/classification/clf1.csv --target_column group --selectkbest_num_features 32 --training_type clf --test_size 0.2 --feature_selection_method addition --output_dir data/classification/Experiment4/no_feature_selection_addition --output_base clf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [05:57<00:00, 39.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: MLPClassifier\n",
      "Best model cross validation score: 0.9685672434312919\n",
      "\n",
      "Training Models with featuring selection on data\n",
      "run_train_pipeline --input_file data/classification/clf1.csv --target_column group --selectkbest_num_features 32 --training_type clf --test_size 0.2 --feature_selection_method addition --output_dir data/classification/Experiment4/feature_selection_addition --feature_selection --engineer_new_features --output_base clf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [02:06<00:00, 14.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n",
      "Best model cross validation score: 0.926847935548842\n",
      "run_train_pipeline --input_file data/classification/clf1.csv --target_column group --selectkbest_num_features 32 --training_type clf --test_size 0.2 --feature_selection_method elimination --output_dir data/classification/Experiment4/feature_selection_elimination --feature_selection --engineer_new_features --output_base clf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [02:08<00:00, 14.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n",
      "Best model cross validation score: 0.926847935548842\n"
     ]
    }
   ],
   "source": [
    "# Run Experiments\n",
    "data_path = \"data/classification/clf1.csv\"\n",
    "for experiment_name, config in tqdm(experiment_config.items()):\n",
    "    print(f\"\\nTraining Models {experiment_name} on data\")\n",
    "    \n",
    "    engineer_new_features = config[\"engineer_new_features\"]\n",
    "    feature_selection = config[\"feature_selection\"]\n",
    "    feature_selection_methods = config[\"feature_selection_method\"]\n",
    "\n",
    "    for feature_selection_method in feature_selection_methods:\n",
    "        outdir = config[\"output_dir\"] + f\"_{feature_selection_method}\"\n",
    "        # run experiment\n",
    "        run_train_pipeline(input_file = data_path,  \n",
    "                           target_column = \"group\",\n",
    "                           input_type = \"csv\",\n",
    "                           training_type = \"clf\",\n",
    "                           engineer_new_features=engineer_new_features,\n",
    "                           output_base=\"\",\n",
    "                           test_size=0.2, \n",
    "                           no_standard_scaling=False,\n",
    "                           feature_selection=feature_selection, \n",
    "                           feature_selection_method=feature_selection_method,\n",
    "                           selectkbest_num_features=32, \n",
    "                           output_dir=outdir\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7ea9e37-3dcf-4ac4-91bd-0b7e81fe02f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Experimental Results For Publishing\n",
    "# Check research papers for the types of plots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
